---
title: "Initial Review of DEP Irradiance Data"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership."
date: "04/26/2021"
output:
  github_document:
    toc: true
    fig_width: 5
    fig_height: 4
---

<img
    src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
    style="position:absolute;top:10px;right:50px;" />

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center',
                      fig.width = 5, fig.height = 4,
                      collapse = TRUE, comment = "#>")
```

# Introduction
Review of irradiance data and calculation of light attenuation coefficients.
(k values.)

Light attenuation is often measured as 
$$
I_d = I_0 e^{-kz}
$$
Where $z$ is depth.

$$
\frac{I_d}{I_0} = e^{-kz}
$$


$$
log(\frac{I_d}{I_0}) = -kz
$$


Note that this produces a value of k at each depth  If we assume theory is
accurate and light attenuation is vertically uniform, we can average across 
depths. to improve accuracy. 

$$ k = \frac{1}{-z} \times log(\frac{I_d}{I_0}) $$

Where we recast values as percentages of surface light, we can estimate k~d as

$$ k \approx - \frac{log(I_d)}{z}$$

We want to recast that as a linear regression problem.

Y = mx + b

log(Id) = -kz

So, K can be estimated as the negative of linear coefficient of depth in a 
linear model.


#Load libraries
```{r}
#library(readxl)
library(tidyverse)

library(GGally)
library(emmeans)
#library(mgcv)

library(CBEPgraphics)
load_cbep_fonts()
theme_set(theme_cbep())
```

# Load Data
```{r}
irr_data <- read_csv(file.path('dep_irradiance_data.csv')) %>%
              rename(sample_date = dt)
```

# Summary of Metadata
## QA/QC Samples
We conducted no analysis of QA/QC samples, and simply deleted then from the data
to avoid confusion.

## Censoring Flags
While preparing our working data, we separated raw observations from text
annotations, including data quality flags.  IN the sonde-related data, we only
had to contend with (1) left censoring of turbidity data , and (2) data quality 
flags on all chlorophyll data.

Since all sonde-related chlorophyll data was flagged as of questionable 
accuracy (with "J" flags), it does us no good to track that information during 
further analysis.  We retain all data, but recognize that it's accuracy is 
suspect, especially in comparison to laboratory results.

We also had a few "U<"  flags in the Turbidity data.  We separated out a 
`TRUE` / `FALSE` flag to indicated censored values, with the name 
'turbidity_cens`.

## Units
Our derived data files lack any indication of units.  Units were documented
in the source Excel files.  We summarize relevant information here.

Variable Name |  Meaning                 | Units                 |  
--------------|--------------------------|-----------------------|  
site_name     | DEP "Site ID"            |                       |  
site          | DEP "Sample Point ID" without depth designation |    |  
sample_date   | Date of sample collection    | yyyy-mm-dd format     |
month     | Month, derived from date     | Three letter codes    |
year      | Year, derived from date      |                  |    |
time      | time of sample               | 24 hour clock, hh:mm format |
hour      | hour, derived from time      |                       |
depth     | Sample Depth	               | Meters                |
irr_air   | Irradiance (air)              | µmol/m2/s            |
irr_water | Irradiance (surface water)    | µmol/m2/s            |
irr_pct_  | Irradiance (% of air in surface water) | %           |


# Review of Irradiance Data
## Scatterplot Matrix (Pairs Plot)
```{r fig.width = 5, fig.height = 5 }
tmp <- irr_data %>%
  select(irr_air:irr_pct)
ggpairs(log(tmp), progress = FALSE)
```
Note skewed data distributions, even for the percentage values.

## Sites by Depths (Useless?) 
```{r}
tmp <- irr_data %>%
  mutate(dpth_clss = if_else(depth < 2, round(depth, 1), round(depth,0)))
xtabs(~ dpth_clss + site, data = tmp)
rm(tmp)
```

It appears there are several different sampling conventions combined here:
*  Sampling with downcast at uneven shallow depths
*  Sampling at shallow half meter intervals to two meters and at
   one meter intervals beyond that point.

## How often was each site sampled?
We make an assumption here that sampling on one day is all related.
```{r}
tmp <- irr_data %>%
  group_by(site, sample_date) %>%
  summarize(was_sampled = sum(! is.na(depth)) > 1,
            .groups = 'drop')
xt <- xtabs(~ sample_date + site, data = tmp)
tot <- colSums(xt)
tot
```

We identify the sites with the richest data history, and focus on them.
```{r}
(preferred_sites <- names(tot[tot > 20]))
rm(tmp, xt)
```

We see clearly that certain sites had data collected much more frequently.
These are the same sites for which we have more abundant sonde data.  we 
will need to correlate these data in some intelligent way.

```{r}
irr_data %>%
  filter(year == 2018) %>%
  filter(site %in% preferred_sites) %>%
ggplot(aes(sample_date, depth, color = irr_water)) +
  geom_jitter(width = 3) +
   scale_colour_gradient(name = "Light (µmol/m2/s)",
                         low = scales::muted("lightblue", l = 10),
                         high = scales::muted("lightblue", l = 80)) +
   scale_y_reverse() +
  theme_cbep(base_size = 12) +
  theme(legend.position = 'bottom',
        legend.title = element_text(size = 12),
        legend.text =  element_text(size = 10),
        axis.ticks.length.x = unit(0, 'in')) +
  guides(color = guide_colourbar(title.position="top", barheight = .5))
  
```

```{r fig.width = 7, fig.height = 5}
irr_data %>%
  filter(year == 2018) %>%
  filter(site %in% preferred_sites) %>%
ggplot(aes(depth, irr_pct, color = factor(sample_date))) +
  geom_point() +
  geom_smooth(se = FALSE, method = 'lm', formula = y ~ x) +
  scale_color_discrete(name = 'Date') +
  xlab('Irradiance') +
  ylab('Depth') +
  scale_y_reverse() +
  scale_x_log10() +
  theme_cbep(base_size = 12) +
  theme(#legend.position = 'bottom',
        legend.title = element_text(size = 12),
        legend.text =  element_text(size = 10),
        axis.ticks.length.x = unit(0, 'in')) +
  #guides(color = guide_colorbar(title.position="top", barheight = .5)) +
  facet_wrap("site")
```
So, lets develop relevant estimates of K.  We want to end up with one value of
k for each unique depth profile.

```{r}
k_data <- irr_data %>%
  filter(site %in% preferred_sites) %>%
  group_by(site, sample_date) %>%
  nest() %>%
  mutate(the_lm = map(data, 
                      function(dat) lm(log(irr_pct) ~ depth, data = dat))) %>%
  mutate(k_est = map(the_lm, 
                     function(mod) -summary(mod)$coef[2, 1]), # extracts slope
         k_se = map(the_lm, 
                     function(mod) summary(mod)$coef[2, 2]), # extracts SE
         k_n =  map(data, 
                     function(dat) sum(! is.na(dat$irr_pct)))
         ) %>%
  mutate(site_name = map(data, function(dat) first(dat$site_name)[[1]]),
         month = map(data, function(dat) first(dat$month)[[1]]),
         year = map(data, function(dat) first(dat$year)[[1]]),
         start_hour = map(data, function(dat) min(dat$hour)[[1]]),
         doy = map(data, 
                   function(dat) as.numeric(format(min(sample_date), 
                                                   format = '%j')))) %>%

  select (-data, -the_lm) %>%
  unnest(everything()) %>%
  relocate(site_name, site, sample_date,  
           year, month, doy, start_hour) %>%
  filter(k_n >4)
```

PRV70	on 2020-09-24 had only two samples , so the regression is dominated by
it is also the only time we have fewer than five light values to base an
estimate of K on. We deleted that date.

```{r fig.width = 6, fig.height = 4}
ggplot(k_data, aes(doy, k_est)) +
  geom_point(aes(color = factor(year))) +
  geom_smooth(method = 'gam', formula = y~ s(x)) +
  geom_linerange(aes(ymin = k_est - k_se, ymax = k_est + k_se)) +
  scale_y_log10() +
  scale_color_manual(values = cbep_colors()) +
  theme_cbep(base_size = 12) +
  facet_wrap("site")
```

We can fit models looking at light attenuation coefficients by site, 
year and day of the year, but site PRV70 is doing something odd, which forces
the model to be fairly complex.  We fit a simplified model that only fits
linear terms by day of the year.

note that we use a weighted regression because we know our K values to different
levels of precision.

```{r}
full_lm <- lm(k_est ~ (site  + doy)^2 + factor(year), 
              weights = 1/(k_se^2), data = k_data)
```

```{r}
anova(full_lm)
summary(full_lm)
```
```{r}
old_par = par(mfrow = c(2,2))
plot(full_lm)
par(old_par)
```

```{r}
no_weights_lm <- lm(k_est ~ (site  + doy)^2 + factor(year), data = k_data)
anova(no_weights_lm)
```

```{r}
old_par = par(mfrow = c(2,2))
plot(no_weights_lm)
par(old_par)
```


```{r}
full_lm_log <- lm(log(k_est) ~ (site  + doy)^2 + factor(year), data = k_data)
anova(full_lm_log)
```

```{r}
old_par = par(mfrow = c(2,2))
plot(full_lm_log)
par(old_par)
```

We extract means and "adjusted" means for comparison purposes.  

# Mean K by Site
These SE estimates are based on the variance of a linear combination of random
variables.
```{r}
k_means <- k_data %>%
  group_by(site) %>%
  summarize(k_n_tot = sum(k_n),
            K_mean  = mean(k_est),
            K_se    = sqrt(sum(k_se^2 / (k_n)^2 )))
k_means
```

# "Adjusted" Mean K by Site
```{r}
(emms <- emmeans(full_lm_log, 'site', at = list(doy = 200), type = 'response'))
```

We have to take that warning about interactions seriously. The interaction
is with day of the year. W e can visualize the pattern like this:
```{r}
emmip(full_lm_log, site ~ doy, variable = 'doy', type = 'response',
      at = list(doy = seq(100, 300, by = 10)), CIs = TRUE) +
  theme_cbep()

```
Basically, differences are greater in the spring, and taper over the course of 
the year, as some relatively high K values drop.  Rank order of differences 
changes mid-summer.  Some of this may reflect the uneven variances.

Notice that K values are highest at the Presumpscot stations, and lowest at the 
Fore River station.

(Remember, we know this model left out some complexity of the day of year
response at PRV70.)

# Compare Results
```{r}
results <- as_tibble(emms) %>%
  left_join(k_means, by = 'site') %>%
  rename(em_mn = response,
         em_se = SE,
         k_mn = K_mean,
         k_se = K_se)
```

```{r}
ggplot(results, aes(k_mn, em_mn)) +
  geom_point() +
  geom_text(aes(label = site), nudge_x = 0.1) +
  geom_linerange(aes(ymin = em_mn - em_se, ymax = em_mn + em_se )) +
  geom_linerange(aes(xmin = k_mn - k_se, xmax = k_mn + k_se )) +
  geom_abline(slope = 1, intercept = 0) +
  xlab('Simple Means') +
  ylab('Estimated Marginal Means')
```
So....  
1.  The "adjusted" marginal means (of a log model) are very close to
    the raw means.  
2.  Rank order are seldom changed.  
3.  Estimated standard errors are themselves fairly consistent, with the errors
    from the complex model a bit larger than the estimates standard error of the 
    means.
4.  We **still** have some evidence for a remaining location-scale relationship. 




We don't yet have a purpose for more complex models or more complex graphics.
We await evaluation of other data before continuing.


